# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных шкалах (некоторые ~0–1, другие ~10–100), что делает масштабирование обязательным

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров (спираль) + явные выбросы, которые KMeans не может отделить

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый равномерный шум, что затрудняет выбор `eps` для DBSCAN

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: для всех датасетов применялся `StandardScaler` к числовым признакам. Пропусков и категориальных признаков не было, поэтому дополнительная обработка не требовалась.
- Поиск гиперпараметров:
  - Для KMeans: `k` в диапазоне 2–10, выбор по максимуму silhouette score.
  - Для DBSCAN: подбор `eps` вручную (0.2–0.6) с фиксированным `min_samples` (5 или 10), выбор также по silhouette score на non-noise точках.
  - Лучшим считалось решение с наибольшим silhouette score, при условии разумного количества кластеров и шума.
- Метрики: рассчитывались `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`. Для DBSCAN метрики считались только на точках, не помеченных как шум (`label != -1`).
- Визуализация: PCA(2D) для каждого датасета с раскраской по кластерам лучшей модели. t-SNE не использовался.

## 3. Models

На каждом из трёх датасетов были сравнены два алгоритма кластеризации: **KMeans** и **DBSCAN**. Для каждого метода проводился подбор гиперпараметров в рамках честного unsupervised-протокола (только на обучающих данных, без использования внешней информации).

### Dataset A (`S07-hw-dataset-01.csv`)
- **KMeans**:  
  - Подбор числа кластеров `k` в диапазоне от 2 до 10.  
  - Фиксированные параметры: `random_state=42`, `n_init=10`.  
  - Выбор лучшего `k` осуществлялся по максимальному значению silhouette score.
- **DBSCAN**:  
  - Перебор параметра `eps` в диапазоне `[0.2, 0.3, 0.4, 0.5, 0.6]`.  
  - Параметр `min_samples` фиксирован как `5` (учитывая умеренную плотность кластеров).  
  - Метрики оценивались только на non-noise точках (`label != -1`).

### Dataset B (`S07-hw-dataset-02.csv`)
- **KMeans**:  
  - Подбор `k` в диапазоне от 2 до 10.  
  - Фиксированные параметры: `random_state=42`, `n_init=10`.  
  - Выбор по silhouette score.
- **DBSCAN**:  
  - Перебор `eps` в диапазоне `[0.2, 0.3, 0.4, 0.5, 0.6]`.  
  - `min_samples=5` — выбрано с учётом наличия выбросов и нелинейной структуры.  
  - Шумовые точки (`label = -1`) исключались при расчёте метрик.

### Dataset C (`S07-hw-dataset-03.csv`)
- **KMeans**:  
  - Подбор `k` в диапазоне от 2 до 10.  
  - Фиксированные параметры: `random_state=42`, `n_init=10`.  
  - Оценка по silhouette score.
- **DBSCAN**:  
  - Перебор `eps` в диапазоне `[0.2, 0.3, 0.4, 0.5, 0.6]`.  
  - `min_samples=10` — увеличенное значение, так как датасет содержит кластеры разной плотности и фоновый шум; более высокое `min_samples` помогает избежать фрагментации плотных кластеров.  
  - Метрики рассчитывались только на ненулевых (non-noise) точках.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, `k=2`
- Метрики (silhouette / DB / CH): silhouette ≈ 0.58, DB ≈ 0.85, CH ≈ 2800
- Если был DBSCAN: доля шума ~15%, но silhouette ниже, чем у KMeans
- Коротко: KMeans выиграл, потому что после масштабирования кластеры стали компактными и сферическими, что соответствует предположениям алгоритма.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, `eps=0.4`, `min_samples=5`
- Метрики (silhouette / DB / CH): silhouette ≈ 0.42, DB ≈ 1.1, CH ≈ 850
- Если был DBSCAN: доля шума ~8%, что соответствует визуальному количеству выбросов
- Коротко: DBSCAN успешно выделил спиральную структуру, тогда как KMeans разрезал её на радиальные сегменты, что не соответствует истинной форме.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN, `eps=0.3`, `min_samples=10`
- Метрики (silhouette / DB / CH): silhouette ≈ 0.51, DB ≈ 0.95, CH ≈ 1200
- Если был DBSCAN: доля шума ~12%, что соответствует фоновому шуму в данных
- Коротко: DBSCAN адаптировался к разной плотности кластеров, в то время как KMeans объединил плотный кластер с частью фона.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на нелинейных формах (dataset-02) и при разной плотности (dataset-03), потому что предполагает выпуклые, одинаково плотные кластеры.
- DBSCAN выигрывает там, где есть выбросы или нелинейность, так как он основан на плотности и не требует задавать число кластеров.
- Наибольшее влияние на результат оказало **масштабирование** (для dataset-01) и **наличие выбросов/плотности** (для dataset-02/03). Без масштабирования KMeans на dataset-01 дал бы бессмысленный результат.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: 5 запусков KMeans на dataset-01 с разными `random_state` (0–4), сравнение через Adjusted Rand Index (ARI).
- Результат: средний ARI = 1.000 ± 0.000, что указывает на полную воспроизводимость.
- Вывод: KMeans устойчив на dataset-01, потому что кластеры хорошо разделены, сферичны и масштабированы.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через визуализацию PCA(2D) и анализ доли шума. Например, в dataset-02 шумовые точки лежали вне основной спирали, что согласуется с их природой как выбросов.
- В dataset-03 плотный кластер был чётко отделён от разреженного фона, что подтверждает адекватность DBSCAN.
- В dataset-01 два кластера были компактными и сбалансированными, что соответствует ожиданиям от KMeans.

## 6. Conclusion

1. Масштабирование обязательно для distance-based методов, особенно KMeans.  
2. KMeans работает только при сферических и равноплотных кластерах; в остальных случаях лучше использовать DBSCAN.  
3. Внутренние метрики (особенно silhouette) полезны, но их нужно интерпретировать в контексте данных (например, игнорировать шум для DBSCAN).  
4. PCA(2D) — минимально достаточная визуализация для проверки гипотез о структуре.  
5. Честный протокол unsupervised-эксперимента требует фиксации препроцессинга, воспроизводимых параметров и объективного критерия выбора модели.  
6. DBSCAN эффективен для данных с выбросами и нелинейной структурой, но чувствителен к выбору `eps`.  
7. Устойчивость моделей можно проверить даже без истинных меток (например, через ARI между запусками).  
8. Кластеризация — это не "автоматическая разметка", а инструмент для генерации гипотез, требующий визуальной и содержательной проверки.