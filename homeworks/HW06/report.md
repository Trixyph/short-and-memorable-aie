# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (10000 строк, 30 столбцов)
- Целевая переменная: `target` (бинарная классификация: 0 и 1)
  - Класс 0: 79.87% (доля: 0.7987)
  - Класс 1: 20.13% (доля: 0.2013)
- Признаки:
  - 24 числовых признака: `num01`-`num24` (стандартизированные числовые значения)
  - 3 категориальных признака: `cat_contract`, `cat_region`, `cat_payment` (закодированные как целые числа)
  - 1 признак продолжительности: `tenure_months` (целое число, время обслуживания в месяцах)
  - Служебный столбец: `id` (не используется как признак)

## 2. Protocol

- Разбиение: train/test (доля test: 0.2, `random_state=42`, стратификация по `target`)
  - Train: 8000 samples
  - Test: 2000 samples
- Подбор гиперпараметров: 5-кратная кросс-валидация на train, оптимизация по ROC-AUC
- Метрики:
  - `accuracy` - общая доля верных предсказаний
  - `f1-score` - гармоническое среднее precision и recall, важен при дисбалансе классов
  - `ROC-AUC` - площадь под ROC-кривой, показывает качество разделения классов, устойчива к дисбалансу

## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier** (baseline):
   - Стратегия: `most_frequent` (всегда предсказывает наиболее частый класс)
   
2. **LogisticRegression** (baseline из S05):
   - Pipeline: `StandardScaler` + `LogisticRegression`
   - `max_iter=1000`, `random_state=42`
   
3. **DecisionTreeClassifier** (контроль сложности):
   - Подбирались параметры: `max_depth`, `min_samples_leaf`, `criterion`
   - Диапазоны: `max_depth` ∈ [3, 5, 7, 10, None], `min_samples_leaf` ∈ [1, 3, 5, 10]
   
4. **RandomForestClassifier**:
   - Подбирались параметры: `n_estimators`, `max_depth`, `min_samples_leaf`, `max_features`
   - Диапазоны: `n_estimators` ∈ [50, 100, 200], `max_depth` ∈ [5, 10, 20, None], `max_features` ∈ ['sqrt', 'log2']
   
5. **AdaBoostClassifier** (boosting):
   - Подбирались параметры: `n_estimators`, `learning_rate`
   - Диапазоны: `n_estimators` ∈ [50, 100, 200], `learning_rate` ∈ [0.01, 0.1, 0.5, 1.0]
   
6. **StackingClassifier** (опционально):
   - Базовые модели: лучшие RandomForest и AdaBoost
   - Мета-модель: LogisticRegression
   - CV для стекинга: 5 фолдов

## 4. Results

Финальные метрики на test-выборке:

| Модель | Accuracy | F1-score | ROC-AUC |
|--------|----------|----------|---------|
| DummyClassifier | 0.7987 | 0.0000 | 0.5000 |
| LogisticRegression | 0.8315 | 0.5369 | 0.9020 |
| DecisionTree | 0.8450 | 0.5925 | 0.8698 |
| RandomForest | 0.8595 | 0.6384 | 0.9429 |
| AdaBoost | 0.8610 | 0.6444 | 0.9440 |
| Stacking | 0.8590 | 0.6372 | 0.9439 |

AdaBoostClassifier (ROC-AUC = 0.9440)

AdaBoost показал наивысший ROC-AUC, что свидетельствует о лучшей способности разделять классы. Также имеет лучшие значения accuracy и F1-score среди всех моделей.

## 5. Analysis

**Устойчивость** (5 прогонов для RandomForest с разными random_state):

| random_state | ROC-AUC |
|--------------|---------|
| 42 | 0.9429 |
| 123 | 0.9420 |
| 777 | 0.9415 |
| 999 | 0.9423 |
| 7 | 0.9418 |

RandomForest показывает стабильные результаты (вариация менее 0.15%) при изменении random_state.

**Ошибки** (confusion matrix лучшей модели - AdaBoost):

- True Negative (TN): 1522
- False Positive (FP): 75
- False Negative (FN): 203
- True Positive (TP): 200

Модель хорошо предсказывает класс 0 (отток), но имеет больше ошибок для класса 1 (вероятно, из-за дисбаланса классов).

**Интерпретация** (permutation importance - top-15 признаков AdaBoost):

1. `tenure_months` (0.203) - наиболее важный признак
2. `num15` (0.039)
3. `num17` (0.038)
4. `cat_contract` (0.033)
5. `num19` (0.030)
6. `num14` (0.023)
7. `num05` (0.022)
8. `num12` (0.020)
9. `num11` (0.019)
10. `num02` (0.018)
11. `cat_payment` (0.017)
12. `num10` (0.017)
13. `num04` (0.017)
14. `num18` (0.015)
15. `num06` (0.014)

1. `tenure_months` (время обслуживания) - самый важный признак для предсказания оттока
2. Категориальные признаки `cat_contract` и `cat_payment` вошли в топ-15
3. Признак `cat_region` не оказался важным
4. Результаты соответствуют бизнес-логике: отток клиентов сильно зависит от времени обслуживания и условий контракта

## 6. Conclusion

1. **Ансамблевые методы превосходят одиночные модели**: RandomForest и AdaBoost показали лучшие результаты по сравнению с DecisionTree и LogisticRegression, демонстрируя силу ансамблей.

2. **Boosting эффективен на несбалансированных данных**: AdaBoost показал наилучший ROC-AUC (0.9440), что важно для задач с дисбалансом классов, где простое accuracy может вводить в заблуждение.

3. **Контроль сложности деревьев важен**: DecisionTree без ограничений (max_depth=None) сильно переобучается, тогда как с контролем сложности показывает более стабильные результаты.

4. **Интерпретируемость моделей**: Permutation importance позволяет выявить наиболее важные признаки, что соответствует бизнес-интуиции (время обслуживания - ключевой фактор оттока).

5. **Воспроизводимость эксперимента**: Фиксация random_state и использование стратификации обеспечивают воспроизводимость результатов, что критически важно для научного подхода в ML.

6. **Правильный протокол оценки**: Использование отдельного test-набора только для финальной оценки и подбор гиперпараметров через CV на train предотвращает "утечку" данных и дает честную оценку качества моделей.