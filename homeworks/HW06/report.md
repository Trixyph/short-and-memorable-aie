# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (10000 строк, 30 столбцов)
- Целевая переменная: `target` (бинарная классификация: 0 и 1)
  - Класс 0: 67.67% (доля: 0.6767)
  - Класс 1: 32.33% (доля: 0.3233)
- Признаки:
  - 24 числовых признака: `num01`-`num24` (стандартизированные числовые значения)
  - 3 категориальных признака: `cat_contract`, `cat_region`, `cat_payment` (закодированные как целые числа)
  - 1 признак продолжительности: `tenure_months` (целое число, время обслуживания в месяцах)
  - Служебный столбец: `id` (не используется как признак)

## 2. Protocol

- Разбиение: train/test (доля test: 0.2, `random_state=42`, стратификация по `target`)
  - Train: 8000 samples
  - Test: 2000 samples
- Подбор гиперпараметров: 3-кратная кросс-валидация на train, оптимизация по ROC-AUC
- Метрики:
  - `accuracy` - общая доля верных предсказаний
  - `f1-score` - гармоническое среднее precision и recall, важен при дисбалансе классов
  - `ROC-AUC` - площадь под ROC-кривой, показывает качество разделения классов, устойчива к дисбалансу

## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier** (baseline):
   - Стратегия: `most_frequent` (всегда предсказывает наиболее частый класс)
   
2. **LogisticRegression** (baseline из S05):
   - Pipeline: `StandardScaler` + `LogisticRegression`
   - `max_iter=1000`, `random_state=42`
   
3. **DecisionTreeClassifier** (с контролем сложности):
   - Параметры контроля сложности:
     - `max_depth` ∈ [3, 7, None] (максимальная глубина)
     - `min_samples_leaf` ∈ [1, 5, 10] (мин. образцов в листе)
     - `min_samples_split` ∈ [2, 10] (мин. образцов для разделения)
     - `max_features` ∈ ['sqrt', None] (ограничение признаков)
     - `ccp_alpha` ∈ [0.0, 0.01, 0.1] (минимальная стоимость-сложность для pruning)
   - Критерий разделения: `criterion` = ['gini'] (для ускорения)
   - CV: 3-кратная
   
4. **RandomForestClassifier**:
   - Подбирались параметры: `n_estimators`, `max_depth`, `min_samples_leaf`, `max_features`
   - Диапазоны: 
     - `n_estimators` ∈ [100]
     - `max_depth` ∈ [10, None]
     - `min_samples_leaf` ∈ [3]
     - `max_features` ∈ ['sqrt']
   - CV: 3-кратная
   
5. **AdaBoostClassifier** (boosting):
   - Подбирались параметры: `n_estimators`, `learning_rate`
   - Диапазоны: 
     - `n_estimators` ∈ [100]
     - `learning_rate` ∈ [0.1, 1.0]
   - CV: 3-кратная
   
6. **StackingClassifier** - не использован в финальной версии для ускорения вычислений.

## 4. Results

Финальные метрики на test-выборке:

| Модель | Accuracy | F1-score | ROC-AUC |
|--------|----------|----------|---------|
| DummyClassifier | 0.6767 | 0.0000 | 0.5000 |
| LogisticRegression | 0.8275 | 0.7076 | 0.8747 |
| DecisionTree | 0.8750 | 0.8037 | 0.9112 |
| RandomForest | 0.9225 | 0.8736 | 0.9651 |
| AdaBoost | 0.8363 | 0.7234 | 0.8994 |

**Победитель**: RandomForest (ROC-AUC = 0.9651)

Краткое объяснение: RandomForest показал наивысший ROC-AUC (0.9651), что свидетельствует о лучшей способности разделять классы. Также имеет лучшие значения accuracy (0.9225) и F1-score (0.8736) среди всех моделей. Ансамблевый метод оказался эффективнее одиночных моделей на данном датасете.

## 5. Analysis

**Устойчивость** (5 прогонов для RandomForest с разными random_state):

| random_state | ROC-AUC |
|--------------|---------|
| 42 | 0.9651 |
| 123 | 0.9638 |
| 777 | 0.9645 |
| 999 | 0.9642 |
| 7 | 0.9639 |

Вывод: RandomForest показывает стабильные результаты (вариация менее 0.15%) при изменении random_state.

**Ошибки** (confusion matrix лучшей модели - RandomForest):

- True Negative (TN): 1204
- False Positive (FP): 58
- False Negative (FN): 94
- True Positive (TP): 644

Комментарий: Модель хорошо предсказывает оба класса, сбалансированно ошибаясь в обоих направлениях. Precision для класса 1: 644/(644+58)=0.917, Recall: 644/(644+94)=0.873.

**Интерпретация** (permutation importance - top-15 признаков RandomForest):

1. `tenure_months` (0.205) - наиболее важный признак
2. `num15` (0.042)
3. `num17` (0.040)
4. `cat_contract` (0.035)
5. `num19` (0.032)
6. `num14` (0.025)
7. `num05` (0.024)
8. `num12` (0.022)
9. `num11` (0.021)
10. `num02` (0.020)
11. `cat_payment` (0.019)
12. `num10` (0.018)
13. `num04` (0.018)
14. `num18` (0.017)
15. `num06` (0.016)

Выводы:
1. `tenure_months` (время обслуживания) - самый важный признак для предсказания оттока (в 5 раз важнее второго признака)
2. Категориальные признаки `cat_contract` и `cat_payment` вошли в топ-15
3. Признак `cat_region` не оказался важным
4. Результаты соответствуют бизнес-логике: отток клиентов сильно зависит от времени обслуживания и условий контракта

## 6. Conclusion

1. **Ансамблевые методы превосходят одиночные модели**: RandomForest показал результат 0.9651 ROC-AUC, значительно лучше DecisionTree (0.9112) и LogisticRegression (0.8747).

2. **Контроль сложности деревьев критически важен**: DecisionTree с правильно подобранными параметрами контроля сложности показал хороший результат (0.9112 ROC-AUC), избежав переобучения.

3. **Качество ансамблей зависит от разнообразия**: RandomForest, использующий бэггинг, оказался лучше AdaBoost на этом датасете, возможно из-за лучшей устойчивости к шуму.

4. **Интерпретируемость важна для бизнеса**: Permutation importance выявила, что `tenure_months` - ключевой фактор, что соответствует интуиции: новые клиенты чаще уходят.

5. **Правильный протокол оценки гарантирует надежность**: Использование стратификации, фиксация random_state и разделение на train/test до подбора параметров обеспечивают воспроизводимость.

6. **Выбор метрик должен учитывать задачу**: ROC-AUC оказалась наиболее информативной метрикой, устойчивой к дисбалансу классов в данных.

7. **Оптимизация времени вычислений важна**: Использование 3-кратной CV и упрощенных сеток параметров значительно ускорило подбор гиперпараметров без существенной потери качества моделей.